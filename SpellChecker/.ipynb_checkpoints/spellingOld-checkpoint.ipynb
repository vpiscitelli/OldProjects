{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improving Spell Checker\n",
    "My program starts with a spelling corrector written by Peter Norvig which can correct a word to what the user might have meant to type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Spelling Corrector\n",
    "# this code is by Peter Norvig \n",
    "# norvig.com/spell-correct.html\n",
    "\n",
    "# this code can take a word and correct it. Sometimes the word is already correct and it ought to\n",
    "# stay the same, or if it is wrong, it will change it to what has the highest probability of being\n",
    "# correct. One issue with his solution is that he doesn't account for words that typically come\n",
    "# after other words.\n",
    "\n",
    "import re, collections\n",
    "\n",
    "def words(text): return re.findall('[a-z]+', text.lower()) \n",
    "\n",
    "def train(features):\n",
    "    model = collections.defaultdict(lambda: 1)\n",
    "    for f in features:\n",
    "        model[f] += 1\n",
    "    return model\n",
    "\n",
    "NWORDS = train(words(file('big.txt').read()))\n",
    "\n",
    "alphabet = 'abcdeÃ©fghijklmnopqrstuvwxyz'\n",
    "\n",
    "def edits1(word):\n",
    "   splits     = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "   deletes    = [a + b[1:] for a, b in splits if b]\n",
    "   transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)>1]\n",
    "   replaces   = [a + c + b[1:] for a, b in splits for c in alphabet if b]\n",
    "   inserts    = [a + c + b     for a, b in splits for c in alphabet]\n",
    "   return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def known_edits2(word):\n",
    "    return set(e2 for e1 in edits1(word) for e2 in edits1(e1) if e2 in NWORDS)\n",
    "\n",
    "def known(words): return set(w for w in words if w in NWORDS)\n",
    "\n",
    "def correct(word):\n",
    "    candidates = known([word]) or known(edits1(word)) or known_edits2(word) or [word]\n",
    "    return max(candidates, key=NWORDS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'will'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct(\"wil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First Improvement:\n",
    "Instead of working on just a single word, I add the ability to correct a whole sentence. The issue with this is that each word is still being corrected on an individual level with no respect for the words that come before or after it. Maybe the user typed the word 'cat' but meant the word 'bat' which based on the context of the surrounding words would be obvious. Otherwise, the word 'cat' is spelt correctly so the spell checker would just leave it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentenceCorrect(string):\n",
    "    word = [] # holds a word\n",
    "    sentence = [] # holds the entire sentence in correct format\n",
    "    \n",
    "    # convert input into a list of words\n",
    "    for i in range(len(string)):\n",
    "        if string[i] == ' ': # store word once a space is found\n",
    "            w = ''.join(word)\n",
    "            sentence.append(w)\n",
    "            word = []\n",
    "        else: # if not a space yet, keep adding on characters\n",
    "            word.append(string[i])\n",
    "    \n",
    "    # get last word added into sentence\n",
    "    if word != []:\n",
    "        w = ''.join(word)\n",
    "        sentence.append(w)\n",
    "        word = []\n",
    "    \n",
    "    # correct each word in sentence\n",
    "    for i in range(len(sentence)):\n",
    "        print correct(sentence[i]), # corrects sentence and then prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish for thought\n"
     ]
    }
   ],
   "source": [
    "sentenceCorrect(\"fsh fod thouht\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to make the spell checker make corrections based off of the surrounding words, I've got to keep track of what words tend to come after other words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this will be a word that will be stored in a dictionary that keeps track of the past 10 words used\n",
    "# right after it. By only keeping a limited number of words, the spell checker can change as the user \n",
    "# changes how he/she writes over time.\n",
    "class Word(object):\n",
    "    name = []\n",
    "    wordsAfter = []\n",
    "    \n",
    "    def __init__(self, word):\n",
    "        self.name = word\n",
    "        \n",
    "    def addWordsAfter(self, word):\n",
    "        self.wordsAfter.append(word)\n",
    "        \n",
    "        # for now, a limit of the past 10 words used right after.\n",
    "        if len(self.wordsAfter) > 40:\n",
    "            self.wordsAfter.pop(0)\n",
    "            \n",
    "    def printWordsAfter(self):\n",
    "        for i in range(len(self.wordsAfter)):\n",
    "            print self.wordsAfter[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class myDictionary(object):\n",
    "    filename = \"\"\n",
    "    fDict = dict()\n",
    "    \n",
    "    def __init__(self, fn):\n",
    "        filename = fn\n",
    "        \n",
    "        f = open(filename, 'r')\n",
    "        words = map(lambda l: l.split(\" \"), f.readlines()) # reads in file and stores each word in words\n",
    "        \n",
    "        iMax = len(words)\n",
    "        for i in range(iMax):\n",
    "            jMax = len(words[i])\n",
    "            for j in range(jMax):\n",
    "                    \n",
    "                if words[i][j] not in self.fDict: # if word from file is not in dictionary yet   \n",
    "                    self.fDict[words[i][j]] = Word(words[i][j]) # add it to the dictionary using Word class as def above\n",
    "                    \n",
    "                # add the word that comes after current word to list\n",
    "                if j < jMax - 1: # if not at last word on line\n",
    "                    if words[i][j + 1] != '':\n",
    "                        self.fDict[words[i][j]].addWordsAfter(words[i][j + 1])\n",
    "                elif i < iMax - 1: # if last word in line, look at first word on next line\n",
    "                    if words[i + 1][0] != '':\n",
    "                        self.fDict[words[i][j]].addWordsAfter(words[i + 1][0])\n",
    "    \n",
    "        #print self.fDict['Emperor'].wordsAfter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apprehensive',\n",
       " 'terminate',\n",
       " 'wilful',\n",
       " 'conveniently',\n",
       " \"'n'\",\n",
       " 'cleanliness',\n",
       " 'collective',\n",
       " 'angela',\n",
       " 'filth',\n",
       " 'philippines',\n",
       " 'timely',\n",
       " 'herein',\n",
       " 'ignoble',\n",
       " 'canton',\n",
       " 'lamentations',\n",
       " 'moslem',\n",
       " 'ware',\n",
       " 'adjective',\n",
       " 'glen',\n",
       " 'invade',\n",
       " 'livid',\n",
       " 'buggy',\n",
       " 'prolong',\n",
       " 'weaken',\n",
       " 'folio',\n",
       " 'dismissal',\n",
       " 'quay',\n",
       " 'enchanting',\n",
       " 'heave',\n",
       " 'purified',\n",
       " 'syrian',\n",
       " 'significantly',\n",
       " 'experimental',\n",
       " 'film',\n",
       " 'repressed',\n",
       " 'cooperation',\n",
       " 'sequel',\n",
       " 'wench',\n",
       " 'calves',\n",
       " '\\n']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish = myDictionary(\"bigEdit.txt\")\n",
    "fish.fDict['The'].wordsAfter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Spell Checker\n",
    "by Vance Piscitelli for CS 482  \n",
    "  \n",
    "My program starts with a spelling corrector written by Peter Norvig which can correct a word to what the user might have meant to type. I improve it by keeping track of the past n words that immediately follow in the provided text file. \n",
    "## Brief Summary of How it Works  \n",
    "<b>word Z:</b> A misspelled word that needs to be corrected.  \n",
    "<b>word X:</b> A correctly spelt word that comes immediately before word Z.  \n",
    "<b>word Y:</b> A correctly spelt word that has frequently come after word X.  \n",
    "When correcting word Z, if it is similar enough to word Y, then word Y will be used as the correction to Word Z.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Original Spelling Corrector</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Spelling Corrector\n",
    "# this code is by Peter Norvig \n",
    "# norvig.com/spell-correct.html\n",
    "\n",
    "# this code can take a word and correct it. Sometimes the word is already correct and it ought to\n",
    "# stay the same, or if it is wrong, it will change it to what has the highest probability of being\n",
    "# correct. One issue with his solution is that he doesn't account for words that typically come\n",
    "# after other words.\n",
    "\n",
    "import re, collections\n",
    "\n",
    "def words(text): return re.findall('[a-z]+', text.lower()) \n",
    "\n",
    "def train(features):\n",
    "    model = collections.defaultdict(lambda: 1)\n",
    "    for f in features:\n",
    "        model[f] += 1\n",
    "    return model\n",
    "\n",
    "# trains the model based of off the specified text file\n",
    "NWORDS = train(words(file('big.txt').read()))\n",
    "\n",
    "# a-z plus some special characters that I added\n",
    "alphabet = 'abcdeÃ©fghijklmnopqrstuvwxyz'\n",
    "\n",
    "# returns words that are 1 edit away\n",
    "def edits1(word):\n",
    "   splits     = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "   deletes    = [a + b[1:] for a, b in splits if b]\n",
    "   transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)>1]\n",
    "   replaces   = [a + c + b[1:] for a, b in splits for c in alphabet if b]\n",
    "   inserts    = [a + c + b     for a, b in splits for c in alphabet]\n",
    "   return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "# returns words that are 2 edits away\n",
    "def known_edits2(word):\n",
    "    return set(e2 for e1 in edits1(word) for e2 in edits1(e1) if e2 in NWORDS)\n",
    "\n",
    "# returns the word if it exists in the list of known words\n",
    "def known(words): return set(w for w in words if w in NWORDS)\n",
    "\n",
    "def correct(word):\n",
    "    candidates = known([word]) or known(edits1(word)) or known_edits2(word) or [word]\n",
    "    return max(candidates, key=NWORDS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apples'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct(\"appees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Sentence Correction:</b>  \n",
    "Instead of working on just a single word, I add the ability to correct a whole sentence. The issue with this is that each word is still being corrected on an individual level with no respect for the other words. Maybe the user typed 'qat' but meant the word 'bat' which based on the context of the surrounding words would be obvious. However, the spell checker might end up selecting 'cat' as being the correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentenceCorrect(string):\n",
    "    word = [] # holds a word\n",
    "    sentence = [] # holds the entire sentence in correct format\n",
    "    \n",
    "    # convert input into a list of words\n",
    "    for i in range(len(string)):\n",
    "        if string[i] == ' ': # store word once a space is found\n",
    "            w = ''.join(word)\n",
    "            sentence.append(w)\n",
    "            word = []\n",
    "        else: # if not a space yet, keep adding on characters\n",
    "            word.append(string[i])\n",
    "    \n",
    "    # get last word added into sentence\n",
    "    if word != []:\n",
    "        w = ''.join(word)\n",
    "        sentence.append(w)\n",
    "        word = []\n",
    "    \n",
    "    # correct each word in sentence\n",
    "    for i in range(len(sentence)):\n",
    "        print correct(sentence[i]), # corrects sentence and then prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish for thought\n"
     ]
    }
   ],
   "source": [
    "sentenceCorrect(\"fsh fod thouht\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating Word Objects</b>  \n",
    "In order to make the spell checker actually make corrections that takes the previous word into consideration, I've got to keep track of what words tend to come after other words. For example, if in the text file the word 'tree' comes after the word 'apple' eight times and the word 'sauce' comes after the word 'apple' only two times, the program should keep track of that. In order to keep track of this information, I created a word object that has a list of the past n words that occurred immediately after the given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this will be a word that will be stored in a dictionary that keeps track of the past n words used\n",
    "# right after it. By only keeping a limited number of words, the spell checker can change as the user \n",
    "# changes how he/she writes over time.\n",
    "class Word(object):\n",
    "    name = []\n",
    "    wordsAfter = []\n",
    "    \n",
    "    def __init__(self, word):\n",
    "        self.name = word\n",
    "        \n",
    "    def addWordsAfter(self, word):\n",
    "        self.wordsAfter.append(word)\n",
    "        \n",
    "        # for now, a limit of the past n words used right after.\n",
    "        if len(self.wordsAfter) > 100:\n",
    "            self.wordsAfter.pop(0)\n",
    "            \n",
    "    def printWordsAfter(self):\n",
    "        for i in range(len(self.wordsAfter)):\n",
    "            print self.wordsAfter[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding a Dictionary</b>  \n",
    "An individual word is not very helpful on its own and the text file has thousands of different words so I used a dictionary to hold all of the word objects. This results in one word object for each different word in the text file along with the words that came immediately after it each time a word was encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keeps track of each word and the words most commonly used after it\n",
    "class myDictionary(object):\n",
    "    filename = \"\"\n",
    "    fDict = dict()\n",
    "    \n",
    "    def __init__(self, fn):\n",
    "        filename = fn\n",
    "        \n",
    "        f = open(filename, 'r')\n",
    "        words = map(lambda l: l.split(), f.readlines()) # reads in file and stores each word in words\n",
    "        \n",
    "        print len(words)\n",
    "        print len(words[0])\n",
    "        # convert all words to lower case\n",
    "        for i in range(len(words)):\n",
    "            for j in range(len(words[i])):\n",
    "                words[i][j] = words[i][j].lower()\n",
    "                if words[i][j].count('\\\\n') > 0:\n",
    "                    words[i][j].pop()\n",
    "                    words[i][j].pop()\n",
    "        \n",
    "        \n",
    "        \n",
    "        iMax = len(words)\n",
    "        for i in range(iMax):\n",
    "            jMax = len(words[i])\n",
    "            for j in range(jMax):\n",
    "                    \n",
    "                if words[i][j] not in self.fDict: # if word from file is not in dictionary yet   \n",
    "                    self.fDict[words[i][j]] = Word(words[i][j]) # add it to the dictionary using Word class as def above\n",
    "                    self.fDict[words[i][j]].wordsAfter = []\n",
    "                    \n",
    "                # add the word that comes after current word to list\n",
    "                if j < jMax - 1: # if not at last word on line\n",
    "                    self.fDict[words[i][j]].addWordsAfter(words[i][j + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Testing the Dictionary</b>  \n",
    "At this point, my program can read through the text file and it keeps track of the past n words that occured after each word. Certain words tend to occur more frequently than other words which the program will use later on. The following code shows that it is indeed keeping track of that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128358\n",
      "10\n",
      "Word: and\n",
      "Words that came immediately after:\n",
      "['independent', 'entirely', 'therefore', 'the', 'so', 'so', 'so', 'an', 'not', 'free', 'cause,', 'the', 'cannot', 'is', 'effect', 'can', 'all', 'inevitability.', 'content,', 'we', 'so', 'we', 'as', 'electricity,', 'so', 'in', 'above', 'in', 'so', 'newton', 'no', 'define', 'then', 'the', 'dissecting', 'enters', 'if', 'of', 'not', 'proved,', 'proved', 'that', 'that', 'such', 'yet', 'geology,', 'the', 'accused', 'stubborn', 'the', 'theology', 'accuses', 'stifles', 'regret', 'in', 'newton,', 'he', 'all', 'church', 'church', 'of', 'cause', 'on', 'to', 'to', 'peace', 'editing', 'how', 'just', 'analyzed,', 'organizations', 'wyoming.', 'fund', \"don't\", 'fund-raising', 'even', 'accept', 'distribute', 'proofread', 'any', 'the', 'expenses,', '[2]', 'exclusions', 'you', 'hold', 'its', 'agents,', 'any', 'distribution', 'expense,', 'all', 'underline', 'additional', 'replacement', 'to', 'licensed', 'trailer', 'may', 'to']\n",
      "\n",
      "Word: or\n",
      "Words that came immediately after:\n",
      "['lesser', 'of', 'argument,', 'as', 'an', 'inevitability,', 'of', 'of', 'of', 'a', 'a', 'highly', 'diminished', 'lesser', 'of', 'business', 'less', 'inevitability', 'lesser', 'more,', 'what', 'even', 'the', 'the', 'self-sacrifice', 'party,', 'an', 'by', 'a', 'less', 'lesser', 'lesser', 'increases', 'lesser', 'lesser', 'lesser', 'short', 'complete', 'from', \"another's,\", 'an', 'mere', 'of', 'chemical', 'heat,', 'the', 'of', 'of', 'the', 'of', 'that', 'certain', 'economic', 'occasioned', 'nonrecognition', 'wrnpc11.zip', 'corrections,', '/etext04,', '90', 'even', 'money', 'payment', 'money', 'forward', 'read', 'reading', 'for', 'other', 'damaged', 'other', 'computer', 'cannot', 'refund\"', 'for', 'contract,', 'incidental', 'implied,', 'any', 'fitness', 'limitation', 'indirectly', 'cause:', 'addition', '[3]', 'by', 'any', 'modify', 'this', 'proprietary', 'hypertext', 'equivalent', 'agree', 'expense,', 'other', 'royalty', 'other', 'other', 'software', 'any', 'from']\n"
     ]
    }
   ],
   "source": [
    "Dictionary = myDictionary(\"bigEdit.txt\")\n",
    "\n",
    "print \"Word:\",\n",
    "print Dictionary.fDict[\"and\"].name\n",
    "print \"Words that came immediately after:\"\n",
    "print Dictionary.fDict[\"and\"].wordsAfter\n",
    "print\n",
    "print \"Word:\",\n",
    "print Dictionary.fDict[\"or\"].name\n",
    "print \"Words that came immediately after:\"\n",
    "print Dictionary.fDict[\"or\"].wordsAfter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Generating Random Sentences</b>  \n",
    "Since I can keep track of the words that come after, I can randomly generate sentences that are somewhat understandable. All the program has to do is pick a random word from the list of words that have come after each word in the sentence. It runs into some issues where it encounters words that were infrequently used, such as only once and that can cause it to end up on a path with only one option each time. This isn't helpful with the main purpose of the program but it was still slightly interesting so I tried it out anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly generated sentence:\n",
      "the goal is one man who have had a moment given to project gutenberg-tm ebooks\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "\n",
    "currentWord = \"the\" # a word to start the sentence with\n",
    "\n",
    "print \"Randomly generated sentence:\"\n",
    "\n",
    "# prints 15 words\n",
    "for i in range(15):\n",
    "    if currentWord != '\\n': # ignore words that are just a new line character\n",
    "        print Dictionary.fDict[currentWord].name,\n",
    "    \n",
    "    numWordsAfter = len(Dictionary.fDict[currentWord].wordsAfter)\n",
    "    if numWordsAfter > 0: # randomly pick the next word\n",
    "        currentWord = Dictionary.fDict[currentWord].wordsAfter[randrange(len(Dictionary.fDict[currentWord].wordsAfter))]\n",
    "    else: # to stop it from having an error, just give it a new word to continue with\n",
    "        currentWord = \"so\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Improving the Spelling Corrector</b>  \n",
    "Now I actually change the spelling corrector to prefer a candidate for correction if it has occurred before. This is done by counting how many times a candidate appears in the list of words that have occurred after the previous word. Most of the code is still the same as before but my changes do make a difference as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Improved Spelling Corrector\n",
    "# edited version of code originally by Peter Norvig \n",
    "# norvig.com/spell-correct.html\n",
    "\n",
    "def wordsB(text): return re.findall('[a-z]+', text.lower()) \n",
    "\n",
    "def trainB(features):\n",
    "    model = collections.defaultdict(lambda: 1)\n",
    "    for f in features:\n",
    "        model[f] += 1\n",
    "    return model\n",
    "\n",
    "NWORDSB = train(wordsB(file('bigEdit.txt').read()))\n",
    "\n",
    "alphabet = 'abcdeÃ©fghijklmnopqrstuvwxyz'\n",
    "\n",
    "def edits1B(word):\n",
    "   splits     = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "   deletes    = [a + b[1:] for a, b in splits if b]\n",
    "   transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)>1]\n",
    "   replaces   = [a + c + b[1:] for a, b in splits for c in alphabet if b]\n",
    "   inserts    = [a + c + b     for a, b in splits for c in alphabet]\n",
    "   return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def known_edits2B(word):\n",
    "    return set(e2 for e1 in edits1B(word) for e2 in edits1B(e1) if e2 in NWORDSB)\n",
    "\n",
    "def knownB(words): return set(w for w in words if w in NWORDSB)\n",
    "\n",
    "def correctB(word):\n",
    "    candidates = knownB([word]) or knownB(edits1B(word)) or known_edits2B(word) or [word]\n",
    "    return max(candidates, key=NWORDSB.get)\n",
    "\n",
    "def correctImprovedB(word, previous):\n",
    "    # get the potential candidates\n",
    "    candidates = knownB([word]) or knownB(edits1B(word)) or known_edits2B(word) or [word]\n",
    "    candidateList = list(candidates)\n",
    "    # check if any of them have been used before after previous word\n",
    "    cCount = []\n",
    "    for i in range(len(candidateList)):\n",
    "        wA = Dictionary.fDict[previous].wordsAfter\n",
    "        c = candidateList[i]\n",
    "        amount = wA.count(c)\n",
    "        cCount.append(amount)\n",
    "    \n",
    "    # get the position of the candidate that has the highest occurance\n",
    "    maxCount = max(cCount)\n",
    "    maxPos = 0\n",
    "    for i in range(len(cCount)):\n",
    "        if cCount[i] == maxCount:\n",
    "            maxPos = i\n",
    "    \n",
    "    # if the highest occurance is >1, then return it\n",
    "    if Dictionary.fDict[previous].wordsAfter.count(candidateList[maxPos]) > 0:\n",
    "        return candidateList[maxPos]\n",
    "    else: # otherwise, just return the closest word\n",
    "        return max(candidates, key=NWORDSB.get)\n",
    "\n",
    "def sentenceCorrectB(string, append):\n",
    "    word = [] # holds a word\n",
    "    sentence = [] # holds the entire sentence in correct format\n",
    "    \n",
    "    # convert input into a list of words\n",
    "    for i in range(len(string)):\n",
    "        if string[i] == ' ': # store word once a space is found\n",
    "            w = ''.join(word)\n",
    "            sentence.append(w)\n",
    "            word = []\n",
    "        else: # if not a space yet, keep adding on characters\n",
    "            word.append(string[i])\n",
    "    \n",
    "    # get last word added into sentence\n",
    "    if word != []:\n",
    "        w = ''.join(word)\n",
    "        sentence.append(w)\n",
    "        word = []\n",
    "    \n",
    "    # correct each word in sentence\n",
    "    # note that the corrected word is added back into the sentence so the next word can use it\n",
    "    for i in range(len(sentence)):\n",
    "        if i == 0: # correct the first word\n",
    "            sentence[i] = correctB(sentence[i]) \n",
    "        else: # correct the remaining words based on the previous words\n",
    "            sentence[i] = correctImprovedB(sentence[i], sentence [i - 1])\n",
    "            \n",
    "        print sentence[i],\n",
    "        \n",
    "    if append == True:\n",
    "        with open(\"bigEdit.txt\", 'a') as f:\n",
    "            f.write(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Simple Test</b>  \n",
    "Now, to run a simple test on it with a variation of a sentence that occurred in the text file:  \n",
    "<b>Original sentence:</b> \"A Frenchman or Russian could not have written that\"  \n",
    "<b>Misspelled:</b> \"A Frenchnan zor Russean coul iot habe writen ohat\"  \n",
    "While the original spelling corrector managed to fix most of the issues, my improved version did a little better, at least in this example.  \n",
    "Note: boolean value indicates whether the result should be appended to the file. Used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a frenchman for russian could it have written that\n",
      "a frenchman or russian could not have written that\n"
     ]
    }
   ],
   "source": [
    "sentence = \"A Frenchnan zor Russean coul iot habe writen ohat\"\n",
    "sentenceCorrect(sentence)\n",
    "print\n",
    "sentenceCorrectB(sentence, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Appending</b>  \n",
    "Now that the sentence is corrected, it could be appended to the text file and each time to program is run, it will start preferring words that are more commonly used by the user. For example, if this was a text messenger, and the user frequently sent \"Hey, how are you?\" then that would become a more likely correction if the user accidentally typed something such as \"Heu, hoq are you?\" as opposed to an incorrect correction like \"Hen, hot are you?\". All that needs to be done is change the boolean value in the sentenceCorrectB() function to True and it will start appending to the file and then just update Dictionary and it will have the most recent changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Future Work</b>  \n",
    "If I was to continue working on this, I would first start by doing more testing to see how much of an improvement it is actually doing as compared to the previous model. I would also change how it keeps track of the words that are commonly used after each word. Right now it is simply a queue of the past n words that were used which works but takes up a lot of space. Lastly, how it decides which word to pick could also be improved but as I already mentioned, I would need better testing in order to figure out how to best improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
